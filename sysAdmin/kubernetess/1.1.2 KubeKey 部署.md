---
tags:
  - k8s
date: "240525"
os: openEuler
---
## 安装

### 基础配置

#### 系统环境配置
- 系统环境
```bash
hostnamectl hostname ksp-master-1
echo "nameserver 114.114.114.114" > /etc/resolv.conf
timedatectl set-timezone Asia/Shanghai
yum install ntpdate -y
ntpdate ntp.aliyun.com
systemctl stop firewalld && systemctl disable firewalld
sed -i 's/^SELINUX=enforcing/SELINUX=disabled/' /etc/selinux/config
setenforce 0
```

- 依赖安装
```bash
yum install curl socat conntrack ebtables ipset ipvsadm tar -y
```

#### 创建新分区

> 服务器新增一块数据盘 /dev/sdb，用于 Containerd 和 Kubernetes Pod 的持久化存储。

```bash
mkfs.xfs /dev/sdb
mkdir /data
mount /dev/sdb /data/
tail -1 /etc/mtab >> /etc/fstab
```

#### 创建数据目录

```bash
mkdir -p /data/openebs/local
mkdir -p /data/containerd
```

- 创建 Containerd 软链接
```bash
ln -s /data/containerd /var/lib/containerd
```

### 安装 KubeKey

#### 下载

```bash
mkdir ~/kubekey
cd ~/kubekey
export KKZONE=cn
curl -sfL https://get-kk.kubesphere.io | sh -
```

#### 查看 KK 支持的 k8s 版本列表

```bash
./kk version --show-supported-k8s
```

#### 创建 k8s 集群部署配置文件

> 本文选择 k8s v1.28.8 ，因此指定配置文件为 `k8s-v1288.yaml`，如果不指定默认名为 `config-sample.yaml`

```bash
./kk create config -f k8s-v1288.yaml --with-kubernetes v1.28.8
```

- 修改配置文件

> 本文示例采用 1 个节点同时作为 control-plane、etcd 和 worker 节点。（因为硬盘容量不足了）

编辑 `k8s-v1288.yaml` 主要修改 kind: Cluster 相关配置
- hosts：指定节点的 IP、ssh
- roleGroups：指定 3 个 etcd、control-plane 节点，复用相同的机器作为 worker 节点
- internalLoadbalancer： 启用内置的 HAProxy 负载均衡器
- domain：自定义域名 **lb.opsxlab.cn**，默认值 **lb.kubesphere.local**
- clusterName：自定义 **opsxlab.cn**，默认值 **cluster.local**
- autoRenewCerts：证书到期自动续期，默认为 **true**
- containerManager：使用 **containerd**

- 修改后的 `k8s-v1288.yaml`
```yaml
apiVersion: kubekey.kubesphere.io/v1alpha2
kind: Cluster
metadata:
  name: sample
spec:
  hosts:
  - {name: ksp-master-1, address: 192.168.9.131, internalAddress: 192.168.9.131, user: root, password: "OpsXlab@2024"}
  - {name: ksp-master-2, address: 192.168.9.132, internalAddress: 192.168.9.132, user: root, password: "OpsXlab@2024"}
  - {name: ksp-master-3, address: 192.168.9.133, internalAddress: 192.168.9.133, user: root, password: "OpsXlab@2024"}
  roleGroups:
    etcd:
    - ksp-master-1
    - ksp-master-2
    - ksp-master-3
    control-plane:
    - ksp-master-1
    - ksp-master-2
    - ksp-master-3
    worker:
    - ksp-master-1
    - ksp-master-2
    - ksp-master-3
  controlPlaneEndpoint:
    ## Internal loadbalancer for apiservers
    internalLoadbalancer: haproxy

    domain: lb.opsxlab.cn
    address: ""
    port: 6443
  kubernetes:
    version: v1.28.8
    clusterName: opsxlab.cn
    autoRenewCerts: true
    containerManager: containerd
  etcd:
    type: kubekey
  network:
    plugin: calico
    kubePodsCIDR: 10.233.64.0/18
    kubeServiceCIDR: 10.233.0.0/18
    ## multus support. https://github.com/k8snetworkplumbingwg/multus-cni
    multusCNI:
      enabled: false
  registry:
    privateRegistry: ""
    namespaceOverride: ""
    registryMirrors: []
    insecureRegistries: []
  addons: []
```

#### 部署k8s

使用上述 .yaml 开始部署

```bash
export KKZONE=cn
./kk create cluster -f k8s-v1288.yaml
```

运行后 kk 会检查 k8s 依赖及其要求，通过检查后输入 yes 继续部署

```bash
[root@ksp-master-1 kubekey]# ./kk create cluster -f k8s-v1288.yaml

14:42:20 CST [GreetingsModule] Greetings
14:42:20 CST message: [ksp-master-2] Greetings, KubeKey!
14:42:21 CST message: [ksp-master-1] Greetings, KubeKey!
14:42:21 CST success: [ksp-master-2]
14:42:21 CST success: [ksp-master-1]
14:42:21 CST [NodePreCheckModule] A pre-check on nodes
14:42:27 CST success: [ksp-master-2]
14:42:27 CST success: [ksp-master-1]
14:42:27 CST [ConfirmModule] Display confirmation form
+--------------+------+------+---------+----------+-------+-------+---------+-----------+--------+--------+------------+------------+-------------+------------------+--------------+
| name         | sudo | curl | openssl | ebtables |
socat | ipset | ipvsadm | conntrack | chrony | docker | containerd | nfs client | ceph client | glusterfs client | time         |
+--------------+------+------+---------+----------+-------+-------+---------+-----------+--------+--------+------------+------------+-------------+------------------+--------------+
| ksp-master-1 | y    | y    | y       | y        | y     | y     | y       | y         | y      |        |            |            |             |                  | CST 14:42:27 |
| ksp-master-2 | y    | y    | y       | y        | y     | y     | y       | y         | y      |        |            |            |             |                  | CST 14:42:22 |
+--------------+------+------+---------+----------+-------+-------+---------+-----------+--------+--------+------------+------------+-------------+------------------+--------------+
```

### 验证 k8s 集群

#### 查看基本状态

- 集群节点信息
```bash
kubectl get nodes -o wide
```

- pod 信息
```bash
kubectl get pods -o wide -A
```

- image 列表
```bash
crictl images ls
```

### 部署 Nginx

#### 创建 Deployment

创建一个具有两个副本，基于 nginx:alpine 的 pod
```bash
kubectl create deployment nginx --image=nginx:alpine --replicas=2
```

#### 创建 Nginx Service

```bash
kubectl create service nodeport nginx --tcp=80:80
```

#### 验证 Deployment 和 Pod

```bash
kubectl get deployment -o wide
kubectl get pods -o wide
```

```bash
NAME    READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES         SELECTOR
nginx   2/2     2            2           84s   nginx        nginx:alpine   app=nginx

NAME                    READY   STATUS    RESTARTS   AGE   IP             NODE           NOMINATED NODE   READINESS GATES
nginx-b4ccb96c6-nlgzb   1/1     Running   0          88s   10.233.116.1   ksp-master-2   <none>           <none>
nginx-b4ccb96c6-nvn52   1/1     Running   0          88s   10.233.84.4    ksp-master-1   <none>           <none>
```

#### 验证 Nginx Service

```bash
kubectl get svc -o wide
```

- 访问
```bash
# 访问 pod
curl 10.233.84.4
curl 10.233.116.1

# 访问 Service
curl 10.233.56.116

# 访问 NodePort
curl 192.168.100.30:32475
curl 192.168.100.31:32475
```
